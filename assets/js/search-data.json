{
  
    
        "post0": {
            "title": "Retail Product Recommendations using word2vec",
            "content": "A person involved in sports-related activities might have an online buying pattern similar to this: . . If we can represent each of these products by a vector, then we can easily find similar products. So, if a user is checking out a product online, then we can easily recommend him/her similar products by using the vector similarity score between the products. . Data gathering and understanding . !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx . df = pd.read_excel(&#39;Online Retail.xlsx&#39;) df.head() . InvoiceNo StockCode Description Quantity InvoiceDate UnitPrice CustomerID Country . 0 536365 | 85123A | WHITE HANGING HEART T-LIGHT HOLDER | 6 | 2010-12-01 08:26:00 | 2.55 | 17850.0 | United Kingdom | . 1 536365 | 71053 | WHITE METAL LANTERN | 6 | 2010-12-01 08:26:00 | 3.39 | 17850.0 | United Kingdom | . 2 536365 | 84406B | CREAM CUPID HEARTS COAT HANGER | 8 | 2010-12-01 08:26:00 | 2.75 | 17850.0 | United Kingdom | . 3 536365 | 84029G | KNITTED UNION FLAG HOT WATER BOTTLE | 6 | 2010-12-01 08:26:00 | 3.39 | 17850.0 | United Kingdom | . 4 536365 | 84029E | RED WOOLLY HOTTIE WHITE HEART. | 6 | 2010-12-01 08:26:00 | 3.39 | 17850.0 | United Kingdom | . Given below is the description of the fields in this dataset: . InvoiceNo: Invoice number, a unique number assigned to each transaction. . | StockCode: Product/item code. a unique number assigned to each distinct product. . | Description: Product description . | Quantity: The quantities of each product per transaction. . | InvoiceDate: Invoice Date and time. The day and time when each transaction was generated. . | CustomerID: Customer number, a unique number assigned to each customer. . | Data Preprocessing . df.isnull().sum() . InvoiceNo 0 StockCode 0 Description 1454 Quantity 0 InvoiceDate 0 UnitPrice 0 CustomerID 135080 Country 0 dtype: int64 . Since we have sufficient data, we will drop all the rows with missing values. . df.dropna(inplace=True) # again check missing values df.isnull().sum() . InvoiceNo 0 StockCode 0 Description 0 Quantity 0 InvoiceDate 0 UnitPrice 0 CustomerID 0 Country 0 dtype: int64 . df[&#39;StockCode&#39;]= df[&#39;StockCode&#39;].astype(str) . customers = df[&quot;CustomerID&quot;].unique().tolist() len(customers) . 4372 . There are 4,372 customers in our dataset. For each of these customers we will extract their buying history. In other words, we can have 4,372 sequences of purchases. . Data Preparation . It is a good practice to set aside a small part of the dataset for validation purpose. Therefore, we will use data of 90% of the customers to create word2vec embeddings. Let&#39;s split the data. . random.shuffle(customers) # extract 90% of customer ID&#39;s customers_train = [customers[i] for i in range(round(0.9*len(customers)))] # split data into train and validation set train_df = df[df[&#39;CustomerID&#39;].isin(customers_train)] validation_df = df[~df[&#39;CustomerID&#39;].isin(customers_train)] . Let&#39;s create sequences of purchases made by the customers in the dataset for both the train and validation set. . purchases_train = [] # populate the list with the product codes for i in tqdm(customers_train): temp = train_df[train_df[&quot;CustomerID&quot;] == i][&quot;StockCode&quot;].tolist() purchases_train.append(temp) . 100%|██████████| 3935/3935 [00:05&lt;00:00, 664.97it/s] . purchases_val = [] # populate the list with the product codes for i in tqdm(validation_df[&#39;CustomerID&#39;].unique()): temp = validation_df[validation_df[&quot;CustomerID&quot;] == i][&quot;StockCode&quot;].tolist() purchases_val.append(temp) . 100%|██████████| 437/437 [00:00&lt;00:00, 1006.50it/s] . Build word2vec Embeddings for Products . model = Word2Vec(window = 10, sg = 1, hs = 0, negative = 10, # for negative sampling alpha=0.03, min_alpha=0.0007, seed = 14) model.build_vocab(purchases_train, progress_per=200) model.train(purchases_train, total_examples = model.corpus_count, epochs=10, report_delay=1) . (3657318, 3696290) . model.save(&quot;word2vec_2.model&quot;) . As we do not plan to train the model any further, we are calling init_sims(), which will make the model much more memory-efficient . model.init_sims(replace=True) . print(model) . Word2Vec(vocab=3153, size=100, alpha=0.03) . Now we will extract the vectors of all the words in our vocabulary and store it in one place for easy access . X = model[model.wv.vocab] X.shape . (3153, 100) . Visualize word2vec Embeddings . It is always quite helpful to visualize the embeddings that you have created. Over here we have 100 dimensional embeddings. We can&#39;t even visualize 4 dimensions let alone 100. Therefore, we are going to reduce the dimensions of the product embeddings from 100 to 2 by using the UMAP algorithm, it is used for dimensionality reduction. . import umap cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0, n_components=2, random_state=42).fit_transform(X) plt.figure(figsize=(10,9)) plt.scatter(cluster_embedding[:, 0], cluster_embedding[:, 1], s=3, cmap=&#39;Spectral&#39;); . . Every dot in this plot is a product. As you can see, there are several tiny clusters of these datapoints. These are groups of similar products. . Generate and validate recommendations . We are finally ready with the word2vec embeddings for every product in our online retail dataset. Now our next step is to suggest similar products for a certain product or a product&#39;s vector. . Let&#39;s first create a product-ID and product-description dictionary to easily map a product&#39;s description to its ID and vice versa. . products = train_df[[&quot;StockCode&quot;, &quot;Description&quot;]] # remove duplicates products.drop_duplicates(inplace=True, subset=&#39;StockCode&#39;, keep=&quot;last&quot;) # create product-ID and product-description dictionary products_dict = products.groupby(&#39;StockCode&#39;)[&#39;Description&#39;].apply(list).to_dict() . products_dict[&#39;84029E&#39;] . [&#39;RED WOOLLY HOTTIE WHITE HEART.&#39;] . We have defined the function below. It will take a product&#39;s vector (n) as input and return top 6 similar products. . Let&#39;s try out our function by passing the vector of the product &#39;90019A&#39; (&#39;SILVER M.O.P ORBIT BRACELET&#39;) . similar_products(model[&#39;90019A&#39;]) . [(&#39;SILVER M.O.P ORBIT DROP EARRINGS&#39;, 0.7879312634468079), (&#39;AMBER DROP EARRINGS W LONG BEADS&#39;, 0.7682332992553711), (&#39;JADE DROP EARRINGS W FILIGREE&#39;, 0.761816143989563), (&#39;DROP DIAMANTE EARRINGS PURPLE&#39;, 0.7489826679229736), (&#39;SILVER LARIAT BLACK STONE EARRINGS&#39;, 0.7389366626739502), (&#39;WHITE VINT ART DECO CRYSTAL NECKLAC&#39;, 0.7352254390716553)] . Cool! The results are pretty relevant and match well with the input product. However, this output is based on the vector of a single product only. What if we want recommend a user products based on the multiple purchases he or she has made in the past? . One simple solution is to take average of all the vectors of the products he has bought so far and use this resultant vector to find similar products. For that we will use the function below that takes in a list of product ID&#39;s and gives out a 100 dimensional vector which is mean of vectors of the products in the input list. . def aggregate_vectors(products): product_vec = [] for i in products: try: product_vec.append(model[i]) except KeyError: continue return np.mean(product_vec, axis=0) . . If you can recall, we have already created a separate list of purchase sequences for validation purpose. Now let&#39;s make use of that. . The length of the first list of products purchased by a user is 314. We will pass this products&#39; sequence of the validation set to the function aggregate_vectors. . Well, the function has returned an array of 100 dimension. It means the function is working fine. Now we can use this result to get the most similar products. Let&#39;s do it. . similar_products(aggregate_vectors(purchases_val[0])) . [(&#39;WHITE SPOT BLUE CERAMIC DRAWER KNOB&#39;, 0.6860978603363037), (&#39;RED SPOT CERAMIC DRAWER KNOB&#39;, 0.6785424947738647), (&#39;BLUE STRIPE CERAMIC DRAWER KNOB&#39;, 0.6783121824264526), (&#39;BLUE SPOT CERAMIC DRAWER KNOB&#39;, 0.6738985776901245), (&#39;CLEAR DRAWER KNOB ACRYLIC EDWARDIAN&#39;, 0.6731897592544556), (&#39;RED STRIPE CERAMIC DRAWER KNOB&#39;, 0.6667704582214355)] . As it turns out, our system has recommended 6 products based on the entire purchase history of a user. Moreover, if you want to get products suggestions based on the last few purchases only then also you can use the same set of functions. . Below we are giving only the last 10 products purchased as input. . similar_products(aggregate_vectors(purchases_val[0][-10:])) . [(&#39;BLUE SPOT CERAMIC DRAWER KNOB&#39;, 0.7394766807556152), (&#39;RED SPOT CERAMIC DRAWER KNOB&#39;, 0.7364704012870789), (&#39;WHITE SPOT BLUE CERAMIC DRAWER KNOB&#39;, 0.7347637414932251), (&#39;ASSORTED COLOUR BIRD ORNAMENT&#39;, 0.7345550060272217), (&#39;RED STRIPE CERAMIC DRAWER KNOB&#39;, 0.7305896878242493), (&#39;WHITE SPOT RED CERAMIC DRAWER KNOB&#39;, 0.6979628801345825)] . References . https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/ | https://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/ | https://www.analyticsinsight.net/building-recommendation-system-using-item2vec/ | https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484 | https://capablemachine.com/2020/06/23/word-embedding/ | .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/sequence%20retail/2021/04/24/rec-medium-word2vec.html",
            "relUrl": "/sequence%20retail/2021/04/24/rec-medium-word2vec.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Recommender System with Node2vec Graph Embeddings",
            "content": "Data gathering and exploration . rating_df = pd.read_csv(&#39;ml100k_ratings.csv&#39;, sep=&#39;,&#39;, header=0) rating_df.head() . userId movieId rating timestamp . 0 1 | 1 | 4.0 | 964982703 | . 1 1 | 3 | 4.0 | 964981247 | . 2 1 | 6 | 4.0 | 964982224 | . 3 1 | 47 | 5.0 | 964983815 | . 4 1 | 50 | 5.0 | 964982931 | . movie_df = pd.read_csv(&#39;ml100k_movies.csv&#39;, sep=&#39;,&#39;, header=0) movie_df.head() . movieId title genres . 0 1 | Toy Story (1995) | Adventure|Animation|Children|Comedy|Fantasy | . 1 2 | Jumanji (1995) | Adventure|Children|Fantasy | . 2 3 | Grumpier Old Men (1995) | Comedy|Romance | . 3 4 | Waiting to Exhale (1995) | Comedy|Drama|Romance | . 4 5 | Father of the Bride Part II (1995) | Comedy | . Neighborhood method . Jaccard Similarity . If we ignore the ratings that the users have given to the movies, and consider the movies that the users have watched, we get a set of movies/users for every user/movie. Think of this formulation as a bipartite graph of users and movies where there is an edge between a user and a movie if a user has watched the movie, the edges have all same weights. . Create a dictionary of movies as keys and values as users that have rated them . Since we have a set of users to characterize each movie, to compute the similarity of two movies, we use Jaccard Index which, for two sets, is the ratio of number of elements in the intersection and number of elements in the union. . def jaccard(movie1, movie2, movie_sets): a = movie_sets[movie1] b = movie_sets[movie2] intersection = float(len(a.intersection(b))) return intersection / (len(a) + len(b) - intersection) . . Let&#39;s explore similarity between some movies, qualitatively. We use the movies dataframe to get the names of the movies via their Ids. . movie_df[movie_df.movieId == 260].title.values[0] . &#39;Star Wars: Episode IV - A New Hope (1977)&#39; . Jaccard distance between &#39;StarWars:EpisodeIV-ANewHope(1977)&#39; and &#39;StarWars:EpisodeV-TheEmpireStrikesBack(1980)&#39; is 0.70 Jaccard distance between &#39;StarWars:EpisodeIV-ANewHope(1977)&#39; and &#39;StarWars:EpisodeVI-ReturnoftheJedi(1983)&#39; is 0.64 Jaccard distance between &#39;StarWars:EpisodeIV-ANewHope(1977)&#39; and &#39;ToyStory(1995)&#39; is 0.40 . The movie Star Wars IV has higher similarity score with other Star Wars as compared to Toy Story. . Using the Jaccard Index, we can retrieve top-k similar movies to a given movie. This provides a way to recommend movies of a user which are similar to the movies that the user has watched. . get_similar_movies_jaccard(260, movie_sets) . {&#39;movie&#39;: &#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;sim_movies&#39;: [&#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;Star Wars: Episode V - The Empire Strikes Back (1980)&#39;, &#39;Star Wars: Episode VI - Return of the Jedi (1983)&#39;, &#39;Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)&#39;, &#39;Matrix, The (1999)&#39;]} . get_similar_movies_jaccard(1, movie_sets) . {&#39;movie&#39;: &#39;Toy Story (1995)&#39;, &#39;sim_movies&#39;: [&#39;Toy Story (1995)&#39;, &#39;Independence Day (a.k.a. ID4) (1996)&#39;, &#39;Jurassic Park (1993)&#39;, &#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;Forrest Gump (1994)&#39;]} . Cosine similarity . Rather than the set based similarity like Jaccard, we can define every movie as a sparse vector of dimension equal to the number of users and the vector entry corresponding to each user is given by the rating that the user has for the movie or zero if no rating exists (i.e. the user hasn&#39;t seen/rated the movie). . print(1.0 - cosine(movie_sparse_vecs[224], movie_sparse_vecs[897])) . 0.8324073552233735 . def get_similar_movies_nbd_cosine(movieid, movie_vecs, top_n=5): movie = movie_df[movie_df.movieId == movieid].title.values[0] movie_idx = movie2id[movieid] query = movie_vecs[movie_idx].reshape(1,-1) ranking = cosine_similarity(movie_vecs,query) top_ids = np.argsort(ranking, axis=0) top_ids = top_ids[::-1][:top_n] top_movie_ids = [movies[j[0]] for j in top_ids] sim_movies = [movie_df[movie_df.movieId == id].title.values[0] for id in top_movie_ids] return {&#39;movie&#39;: movie, &#39;sim_movies&#39;: sim_movies} . . movieid = 1 movie_data = movie_sparse_vecs get_similar_movies_nbd_cosine(movieid, movie_data, top_n=5) . {&#39;movie&#39;: &#39;Toy Story (1995)&#39;, &#39;sim_movies&#39;: [&#39;Toy Story (1995)&#39;, &#39;Toy Story 2 (1999)&#39;, &#39;Jurassic Park (1993)&#39;, &#39;Independence Day (a.k.a. ID4) (1996)&#39;, &#39;Star Wars: Episode IV - A New Hope (1977)&#39;]} . movieid = 260 movie_data = movie_sparse_vecs get_similar_movies_nbd_cosine(movieid, movie_data, top_n=5) . {&#39;movie&#39;: &#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;sim_movies&#39;: [&#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;Star Wars: Episode V - The Empire Strikes Back (1980)&#39;, &#39;Star Wars: Episode VI - Return of the Jedi (1983)&#39;, &#39;Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)&#39;, &#39;Matrix, The (1999)&#39;]} . Factorization method . Singular Value Decomposition . A very popular technique for recommendation systems is via matrix factorization. The idea is to reduce the dimensionality of the data before calculating similar movies/users. We factorize the user-item matrix to obtain the user factors and item factors which are the low-dimensional embeddings such that &#39;similar&#39; user/items are mapped to &#39;nearby&#39; points. . This kind of analysis can generate matches that are impossible to find with the techniques discussed above as the latent factors can capture attributes which are hard for raw data to deciper e.g. a latent factor can correspond to the degree to which a movie is female oriented or degree to which there is a slow development of the charcters. . Moreover, the user and the movies are embedded to the same space, which provides a direct way to compute user-movie similarity. . We will use Singular Value Decomposition (SVD) for factorizing the matrix. . Normalize the rating matrix . normalised_mat = ratings_mat - np.asarray([(np.mean(ratings_mat, 1))]).T . The number of the latent-factors is chosen to be 50 i.e. top-50 singular values of the SVD are considered. The choice of the number of latent factors is a hyperparameter of the model, and requires a more sophisticated analysis to tune. We provide no reason for the choice of 50. . n_factors = 50 A = normalised_mat.T / np.sqrt(ratings_mat.shape[0] - 1) U, S, V = svds(A, n_factors) print(U.shape, V.shape) . (610, 50) (50, 9724) . movie_factors = V.T user_factors = U . Instead of representing each movie as a sparse vector of the ratings of all 360,000 possible users for it, after factorizing the matrix each movie will be represented by a 50 dimensional dense vector. . Define a routine to get top-n movies similar to a given movie. . def get_similar_movies_matrix_factorization(data, movieid, top_n=10): index = movieid - 1 # Movie id starts from 1 movie = movie_df[movie_df.movieId == movieid].title.values[0] movie_row = data[index].reshape(1,-1) similarity = cosine_similarity(movie_row, data) sort_indexes = np.argsort(-similarity)[0] return {&#39;movie&#39;: movie, &#39;sim_movies&#39;: [movie_df[movie_df.movieId == id].title.values[0] for id in sort_indexes[:top_n] + 1]} . . movie_id = 260 get_similar_movies_matrix_factorization(movie_factors, movie_id) . {&#39;movie&#39;: &#39;Priest (1994)&#39;, &#39;sim_movies&#39;: [&#39;Priest (1994)&#39;, &#39;Heidi Fleiss: Hollywood Madam (1995)&#39;, &#39;Reds (1981)&#39;, &#39;I Went Down (1997)&#39;, &#39;Metroland (1997)&#39;, &#39;Love Serenade (1996)&#39;, &#39;Cold Fever (Á köldum klaka) (1995)&#39;, &#39;Suture (1993)&#39;, &#39;Whole Wide World, The (1996)&#39;, &#39;Walking and Talking (1996)&#39;]} . movie_id = 1 get_similar_movies_matrix_factorization(movie_factors, movie_id) . {&#39;movie&#39;: &#39;Toy Story (1995)&#39;, &#39;sim_movies&#39;: [&#39;Toy Story (1995)&#39;, &#39;Back to the Future (1985)&#39;, &#34;Bug&#39;s Life, A (1998)&#34;, &#39;Babe (1995)&#39;, &#39;Star Wars: Episode IV - A New Hope (1977)&#39;, &#39;Who Framed Roger Rabbit? (1988)&#39;, &#39;Mrs. Doubtfire (1993)&#39;, &#39;When Harry Met Sally... (1989)&#39;, &#39;101 Dalmatians (One Hundred and One Dalmatians) (1961)&#39;, &#39;Home Alone (1990)&#39;]} . Since the user and movies are in the same space, we can also compute movies similar to a user. A recommendation model can be defined as showing movies similar to the given user. . def get_recommendations_matrix_factorization(userid, user_factors, movie_factors, top_n=10): user_vec = user_factors[userid - 1].reshape(1,-1) similarity = cosine_similarity(user_vec, movie_factors) sort_indexes = np.argsort(-similarity)[0] return [movie_df[movie_df.movieId == id].title.values[0] for id in sort_indexes[:top_n] + 1] . . top_recos = get_recommendations_matrix_factorization(1, user_factors, movie_factors) top_recos . [&#39;Jungle2Jungle (a.k.a. Jungle 2 Jungle) (1997)&#39;, &#34;Pete&#39;s Dragon (2016)&#34;, &#39;Cellular (2004)&#39;, &#39;Replacement Killers, The (1998)&#39;, &#39;Rough Night (2017)&#39;, &#39;Star Wars: Episode III - Revenge of the Sith (2005)&#39;, &#39;Gentlemen Prefer Blondes (1953)&#39;, &#39;Spanglish (2004)&#39;, &#39;Sorry to Bother You (2018)&#39;, &#39;Planet of the Apes (2001)&#39;] . Graph Embedding method . Create a user-movie graph with edge weights as the ratings. We will use DeepWalk to embed every node of the graph to a low-dimensional space. . user_item_edgelist = rating_df[[&#39;userId&#39;, &#39;movieId&#39;, &#39;rating&#39;]] user_item_edgelist.head() . userId movieId rating . 0 1 | 1 | 4.0 | . 1 1 | 3 | 4.0 | . 2 1 | 6 | 4.0 | . 3 1 | 44 | 5.0 | . 4 1 | 47 | 5.0 | . Create a user-movie weighted graph using python library networkx. . user_movie_graph = nx.Graph() . for x in user_item_edgelist.values: usr = (x[0], &#39;user&#39;) movie = (x[1], &#39;movie&#39;) user_movie_graph.add_node(user2dict[usr]) user_movie_graph.add_node(movie2dict[movie]) user_movie_graph.add_edge(user2dict[usr], movie2dict[movie], weight=float(x[2])) . user_movie_graph.number_of_edges() . 100836 . user_movie_graph.number_of_nodes() . 10334 . DeepWalk . We will use the implementation of DeepWalk provided in node2vec which is a bit different from original DeepWalk e.g. it uses negative sampling whereas the original DeepWalk paper used hierarchical sampling for the skip-gram model. . To create embeddings from the context and non-context pairs, we are using Gensim python library. One can easily use Google word2vec or Facebook fasttext for this task. . import numpy as np import networkx as nx import random class Graph(): def __init__(self, nx_G, is_directed, p, q): self.G = nx_G self.is_directed = is_directed self.p = p self.q = q def node2vec_walk(self, walk_length, start_node): &#39;&#39;&#39; Simulate a random walk starting from start node. &#39;&#39;&#39; G = self.G alias_nodes = self.alias_nodes alias_edges = self.alias_edges walk = [start_node] while len(walk) &lt; walk_length: cur = walk[-1] cur_nbrs = sorted(G.neighbors(cur)) if len(cur_nbrs) &gt; 0: if len(walk) == 1: walk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])]) else: prev = walk[-2] next = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], alias_edges[(prev, cur)][1])] walk.append(next) else: break return walk def simulate_walks(self, num_walks, walk_length): &#39;&#39;&#39; Repeatedly simulate random walks from each node. &#39;&#39;&#39; G = self.G walks = [] nodes = list(G.nodes()) print(&#39;Walk iteration:&#39;) for walk_iter in range(num_walks): print(str(walk_iter+1), &#39;/&#39;, str(num_walks)) random.shuffle(nodes) for node in nodes: walks.append(self.node2vec_walk(walk_length=walk_length, start_node=node)) return walks def get_alias_edge(self, src, dst): &#39;&#39;&#39; Get the alias edge setup lists for a given edge. &#39;&#39;&#39; G = self.G p = self.p q = self.q unnormalized_probs = [] for dst_nbr in sorted(G.neighbors(dst)): if dst_nbr == src: unnormalized_probs.append(G[dst][dst_nbr][&#39;weight&#39;]/p) elif G.has_edge(dst_nbr, src): unnormalized_probs.append(G[dst][dst_nbr][&#39;weight&#39;]) else: unnormalized_probs.append(G[dst][dst_nbr][&#39;weight&#39;]/q) norm_const = sum(unnormalized_probs) try: normalized_probs = [float(u_prob)/norm_const for u_prob in unnormalized_probs] except: normalized_probs = [0.0 for u_prob in unnormalized_probs] return alias_setup(normalized_probs) def preprocess_transition_probs(self): &#39;&#39;&#39; Preprocessing of transition probabilities for guiding the random walks. &#39;&#39;&#39; G = self.G is_directed = self.is_directed alias_nodes = {} for node in G.nodes(): unnormalized_probs = [G[node][nbr][&#39;weight&#39;] for nbr in sorted(G.neighbors(node))] norm_const = sum(unnormalized_probs) try: normalized_probs = [float(u_prob)/norm_const for u_prob in unnormalized_probs] except: print(node) normalized_probs = [0.0 for u_prob in unnormalized_probs] alias_nodes[node] = alias_setup(normalized_probs) alias_edges = {} triads = {} if is_directed: for edge in G.edges(): alias_edges[edge] = self.get_alias_edge(edge[0], edge[1]) else: for edge in G.edges(): alias_edges[edge] = self.get_alias_edge(edge[0], edge[1]) alias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0]) self.alias_nodes = alias_nodes self.alias_edges = alias_edges return def alias_setup(probs): &#39;&#39;&#39; Compute utility lists for non-uniform sampling from discrete distributions. Refer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/ for details &#39;&#39;&#39; K = len(probs) q = np.zeros(K) J = np.zeros(K, dtype=np.int) smaller = [] larger = [] for kk, prob in enumerate(probs): q[kk] = K*prob if q[kk] &lt; 1.0: smaller.append(kk) else: larger.append(kk) while len(smaller) &gt; 0 and len(larger) &gt; 0: small = smaller.pop() large = larger.pop() J[small] = large q[large] = q[large] + q[small] - 1.0 if q[large] &lt; 1.0: smaller.append(large) else: larger.append(large) return J, q def alias_draw(J, q): &#39;&#39;&#39; Draw sample from a non-uniform discrete distribution using alias sampling. &#39;&#39;&#39; K = len(J) kk = int(np.floor(np.random.rand()*K)) if np.random.rand() &lt; q[kk]: return kk else: return J[kk] . . G = Graph(user_movie_graph, is_directed=False, p=1, q=1) . p,q = 1 for DeeWalk as the random walks are completely unbiased. . G.preprocess_transition_probs() . Compute the random walks. . 10 walks for every node. | Each walk of length 80. | . walks = G.simulate_walks(num_walks=10, walk_length=80) . Walk iteration: 1 / 10 2 / 10 3 / 10 4 / 10 5 / 10 6 / 10 7 / 10 8 / 10 9 / 10 10 / 10 . len(walks) . 103340 . Learn Embeddings via Gensim, which creates context/non-context pairs and then Skip-gram. . def learn_embeddings(walks): &#39;&#39;&#39; Learn embeddings by optimizing the Skipgram objective using SGD. Uses Gensim Word2Vec. &#39;&#39;&#39; walks = [list(map(str, walk)) for walk in walks] model = Word2Vec(walks, size=50, window=10, min_count=0, sg=1, workers=8, iter=1) return model.wv . . node_embeddings = learn_embeddings(walks) . The output of gensim is a specific type of key-value pair with keys as the string-ed node ids and the values are numpy array of embeddings, each of shape (50,) . node_embeddings[&#39;0&#39;] . array([-2.1159494e-02, -4.3432057e-01, 6.9623584e-01, 4.8146245e-01, 9.6677847e-02, -3.1050149e-02, 1.9733864e-01, 7.9867625e-01, -6.6979128e-01, 6.5312237e-01, 3.1304079e-01, -1.3411559e-01, -1.5454048e-01, -2.7333325e-01, 1.4711864e-01, 2.2469629e-01, -4.3890166e-01, 2.9871342e-01, -6.9798152e-03, -1.7996507e-02, -6.7855030e-02, -4.3489739e-01, 1.5584855e-01, 7.7486165e-02, 3.7617716e-01, 2.8012756e-01, -8.3905622e-02, -3.5362533e-01, 2.2293477e-01, -1.4108117e-01, 1.6970167e-01, -6.3179672e-01, 1.5170584e-02, 6.1733756e-02, -1.2013953e-01, -2.3064958e-01, 2.4610328e-02, 5.0556450e-04, 2.1398006e-01, -1.0361964e-01, 4.8838145e-01, -3.6318046e-01, -3.1330651e-01, 8.6576389e-03, 1.9654050e-02, -4.6078888e-01, 2.7895319e-01, -1.7853497e-04, -1.7593203e-01, 2.8144377e-01], dtype=float32) . movie1 = str(movie2dict[(260, &#39;movie&#39;)]) movie2 = str(movie2dict[(1196, &#39;movie&#39;)]) 1.0 - cosine(node_embeddings[movie1], node_embeddings[movie2]) . 0.42126354575157166 . movie3 = str(movie2dict[(1210, &#39;movie&#39;)]) 1.0 - cosine(node_embeddings[movie1], node_embeddings[movie3]) . 0.29301050305366516 . movie4 = str(movie2dict[(1, &#39;movie&#39;)]) 1.0 - cosine(node_embeddings[movie1], node_embeddings[movie4]) . 0.5913276672363281 . Since we worked with integer ids for nodes, let&#39;s create reverse mapping dictionaries that map integer user/movie to their actual ids. . reverse_movie2dict = {k:v for v,k in movie2dict.items()} reverse_user2dict = {k:v for v,k in user2dict.items()} . node_vecs = [node_embeddings[str(i)] for i in range(cnt)] node_vecs = np.array(node_vecs) node_vecs.shape . (10334, 50) . Movies similar to a given movie as an evaluation of the system. . def get_similar_movies_graph_embeddings(movieid, movie_embed, top_n=10): movie_idx = movie2dict[movieid] query = movie_embed[movie_idx].reshape(1,-1) ranking = cosine_similarity(query, movie_embed) top_ids = np.argsort(-ranking)[0] top_movie_ids = [reverse_movie2dict[j] for j in top_ids if j in reverse_movie2dict][:top_n] sim_movies = [movie_df[movie_df.movieId == id[0]].title.values[0] for id in top_movie_ids] return sim_movies . . get_similar_movies_graph_embeddings((260, &#39;movie&#39;), node_vecs)[:10] . [&#39;Priest (1994)&#39;, &#39;Heidi Fleiss: Hollywood Madam (1995)&#39;, &#39;My Crazy Life (Mi vida loca) (1993)&#39;, &#39;Before the Rain (Pred dozhdot) (1994)&#39;, &#39;Boys of St. Vincent, The (1992)&#39;, &#39;Last Dance (1996)&#39;, &#39;Awfully Big Adventure, An (1995)&#39;, &#39;Queen Margot (Reine Margot, La) (1994)&#39;, &#34;Widows&#39; Peak (1994)&#34;, &#39;What Happened Was... (1994)&#39;] . get_similar_movies_graph_embeddings((122, &#39;movie&#39;), node_vecs)[:10] . [&#39;Awfully Big Adventure, An (1995)&#39;, &#39;What Happened Was... (1994)&#39;, &#39;Song of the Little Road (Pather Panchali) (1955)&#39;, &#39;Death and the Maiden (1994)&#39;, &#39;Heidi Fleiss: Hollywood Madam (1995)&#39;, &#39;My Crazy Life (Mi vida loca) (1993)&#39;, &#39;Love &amp; Human Remains (1993)&#39;, &#34;It&#39;s My Party (1996)&#34;, &#39;Perez Family, The (1995)&#39;, &#39;Bitter Moon (1992)&#39;] . We can also define the recommendation model based on the cosine similarity i.e the movies are ranked for a given user in terms of the cosine similarities of their corresponding embeddings with the embedding of the user. . def get_recommended_movies_graph_embeddings(userid, node_embed, top_n=10): user_idx = user2dict[userid] query = node_embed[user_idx].reshape(1,-1) ranking = cosine_similarity(query, node_embed) top_ids = np.argsort(-ranking)[0] top_movie_ids = [reverse_movie2dict[j] for j in top_ids if j in reverse_movie2dict][:top_n] reco_movies = [movie_df[movie_df.movieId == id[0]].title.values[0] for id in top_movie_ids] return reco_movies . . get_recommended_movies_graph_embeddings((1, &#39;user&#39;), node_vecs, top_n=10) . [&#39;Best Men (1997)&#39;, &#39;Newton Boys, The (1998)&#39;, &#39;Howard the Duck (1986)&#39;, &#34;Gulliver&#39;s Travels (1939)&#34;, &#39;Shaft (1971)&#39;, &#39;Teenage Mutant Ninja Turtles III (1993)&#39;, &#39;Welcome to Woop-Woop (1997)&#39;, &#39;Song of the South (1946)&#39;, &#39;Three Caballeros, The (1945)&#39;, &#39;Lord of the Rings, The (1978)&#39;] . Evaluation . As another evalution, let&#39;s compare the generated recommendation for a user to the movies tnat the user has actually rated highly. We will get top 10 recommendations for a user, ranked by the cosine similarity, and compute how many of these movies comes from the set of the movies that the user has rated &gt;= 4.5. This tantamounts to Precision@10 metric. For comparison, we will also compute the Precision for the recommendations produced by the matrix factorization model. . idx = 1 recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) recos.intersection(true_pos) . {&#34;Gulliver&#39;s Travels (1939)&#34;, &#39;Lord of the Rings, The (1978)&#39;, &#39;Newton Boys, The (1998)&#39;, &#39;Shaft (1971)&#39;, &#39;Three Caballeros, The (1945)&#39;} . mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) mf_recos.intersection(true_pos) . set() . idx = 2 recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) recos.intersection(true_pos) . {&#39;Dark Knight, The (2008)&#39;, &#39;Inglourious Basterds (2009)&#39;, &#39;The Jinx: The Life and Deaths of Robert Durst (2015)&#39;, &#39;Warrior (2011)&#39;, &#39;Wolf of Wall Street, The (2013)&#39;} . mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) mf_recos.intersection(true_pos) . set() . idx = 3 recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) recos.intersection(true_pos) . {&#39;Alien Contamination (1980)&#39;, &#39;Android (1982)&#39;, &#39;Clonus Horror, The (1979)&#39;, &#39;Death Race 2000 (1975)&#39;, &#39;Galaxy of Terror (Quest) (1981)&#39;, &#39;Hangar 18 (1980)&#39;, &#39;Looker (1981)&#39;, &#39;Master of the Flying Guillotine (Du bi quan wang da po xue di zi) (1975)&#39;, &#39;Saturn 3 (1980)&#39;, &#39;The Lair of the White Worm (1988)&#39;} . mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) mf_recos.intersection(true_pos) . set() . Enriched network with additional information : Genres . Genres of the movies can be used as additional signal for better recommendations . movie_genre_edgelist = movie_df[[&#39;movieId&#39;, &#39;genres&#39;]] movie_genre_edgelist.head() . movieId genres . 0 1 | Adventure|Animation|Children|Comedy|Fantasy | . 1 2 | Adventure|Children|Fantasy | . 2 3 | Comedy|Romance | . 3 4 | Comedy|Drama|Romance | . 4 5 | Comedy | . genre2int . {&#39;(no genres listed)&#39;: 10353, &#39;Action&#39;: 10341, &#39;Adventure&#39;: 10334, &#39;Animation&#39;: 10335, &#39;Children&#39;: 10336, &#39;Comedy&#39;: 10337, &#39;Crime&#39;: 10342, &#39;Documentary&#39;: 10349, &#39;Drama&#39;: 10340, &#39;Fantasy&#39;: 10338, &#39;Film-Noir&#39;: 10352, &#39;Horror&#39;: 10344, &#39;IMAX&#39;: 10350, &#39;Musical&#39;: 10348, &#39;Mystery&#39;: 10345, &#39;Romance&#39;: 10339, &#39;Sci-Fi&#39;: 10346, &#39;Thriller&#39;: 10343, &#39;War&#39;: 10347, &#39;Western&#39;: 10351} . Combine the user-movie and movie-genre graph . user_movie_genre_graph = nx.Graph() user_movie_genre_graph.add_weighted_edges_from([(x,y,user_movie_graph[x][y][&#39;weight&#39;]) for x,y in user_movie_graph.edges()]) user_movie_genre_graph.add_weighted_edges_from([(x,y,movie_genre_graph[x][y][&#39;weight&#39;]) for x,y in movie_genre_graph.edges()]) . user_movie_genre_graph.number_of_edges() . 122882 . G_enriched = Graph(user_movie_genre_graph, is_directed=False, p=1, q=1) G_enriched.preprocess_transition_probs() . walks_enriched = G_enriched.simulate_walks(num_walks=10, walk_length=80) . Walk iteration: 1 / 10 2 / 10 3 / 10 4 / 10 5 / 10 6 / 10 7 / 10 8 / 10 9 / 10 10 / 10 . node_embeddings_enriched = learn_embeddings(walks_enriched) . node_vecs_enriched = [node_embeddings_enriched[str(i)] for i in range(cnt)] node_vecs_enriched = np.array(node_vecs_enriched) node_vecs_enriched.shape . (10354, 50) . get_similar_movies_graph_embeddings((260, &#39;movie&#39;), node_vecs_enriched)[:10] . [&#39;Priest (1994)&#39;, &#39;Mrs. Parker and the Vicious Circle (1994)&#39;, &#39;Last Dance (1996)&#39;, &#39;Tom &amp; Viv (1994)&#39;, &#39;Georgia (1995)&#39;, &#39;My Crazy Life (Mi vida loca) (1993)&#39;, &#39;Before the Rain (Pred dozhdot) (1994)&#39;, &#39;Haunted World of Edward D. Wood Jr., The (1996)&#39;, &#39;To Live (Huozhe) (1994)&#39;, &#39;Vanya on 42nd Street (1994)&#39;] . get_similar_movies_graph_embeddings((260, &#39;movie&#39;), node_vecs)[:10] . [&#39;Priest (1994)&#39;, &#39;Heidi Fleiss: Hollywood Madam (1995)&#39;, &#39;My Crazy Life (Mi vida loca) (1993)&#39;, &#39;Before the Rain (Pred dozhdot) (1994)&#39;, &#39;Boys of St. Vincent, The (1992)&#39;, &#39;Last Dance (1996)&#39;, &#39;Awfully Big Adventure, An (1995)&#39;, &#39;Queen Margot (Reine Margot, La) (1994)&#39;, &#34;Widows&#39; Peak (1994)&#34;, &#39;What Happened Was... (1994)&#39;] . idx = 1 true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) print(len(mf_recos.intersection(true_pos))) ge_recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) print(len(ge_recos.intersection(true_pos))) ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs_enriched, top_n=10)) print(len(ge_enriched_reso.intersection(true_pos))) . 0 5 5 . idx = 8 true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) print(len(mf_recos.intersection(true_pos))) ge_recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) print(len(ge_recos.intersection(true_pos))) ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs_enriched, top_n=10)) print(len(ge_enriched_reso.intersection(true_pos))) . 0 2 1 . idx = 20 true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df[&#39;userId&#39;] == idx) &amp; (rating_df[&#39;rating&#39;] &gt;= 4.5)].movieId.values]) mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors)) print(len(mf_recos.intersection(true_pos))) ge_recos = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs, top_n=10)) print(len(ge_recos.intersection(true_pos))) ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, &#39;user&#39;), node_vecs_enriched, top_n=10)) print(len(ge_enriched_reso.intersection(true_pos))) . 0 0 1 .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/graph%20embedding%20movielens%20factorization/2021/04/24/Recommendation-Node2vec.html",
            "relUrl": "/graph%20embedding%20movielens%20factorization/2021/04/24/Recommendation-Node2vec.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Similar Product Recommender system using Deep Learning for an online e-commerce store",
            "content": ". Import libraries required for file operations . import os import pickle from glob import glob # import basic numerical libraries import numpy as np import pandas as pd # import keras libraries for image recognition from keras.applications import VGG16 from keras.applications.vgg16 import preprocess_input from keras.preprocessing import image as kimage . Data preparation . # download and unzip shirts folder from the directory !wget https://raw.githubusercontent.com/sparsh-ai/rec-data-public/master/shirts.zip !unzip shirts.zip . shirts_dict = dict() for shirt in glob(&#39;shirts/*.jpg&#39;): # load all shirts img = kimage.load_img(shirt, target_size=(224, 224)) # VGG accepts images in 224 X 224 pixels img = preprocess_input(np.expand_dims(kimage.img_to_array(img), axis=0)) # so some preprocessing id = shirt.split(&#39;/&#39;)[-1].split(&#39;.&#39;)[0] shirts_dict[id] = img # map image &amp; shirt id . Number of shirts = 2908 . . Model training . model = VGG16(include_top=False, weights=&#39;imagenet&#39;) shirts_matrix = np.zeros([no_of_shirts, 25088]) # initialize the matrix with zeros for i, (id, img) in enumerate(shirts_dict.items()): shirts_matrix[i, :] = model.predict(img).ravel() # flatten the matrix . Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 58892288/58889256 [==============================] - 0s 0us/step . model.summary() . Model: &#34;vgg16&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, None, None, 3)] 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, None, None, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, None, None, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, None, None, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, None, None, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, None, None, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, None, None, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, None, None, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, None, None, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, None, None, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, None, None, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, None, None, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, None, None, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, None, None, 512) 0 ================================================================= Total params: 14,714,688 Trainable params: 14,714,688 Non-trainable params: 0 _________________________________________________________________ . . Inference pipeline . matrix_id_to_shirt_id = dict() shirt_id_to_matrix_id = dict() for i, (id, img) in enumerate(shirts_dict.items()): matrix_id_to_shirt_id[i] = id shirt_id_to_matrix_id[id] = i . . Finding top 10 similar shirts . Display the sample shirt . from IPython.display import Image Image(&#39;shirts/1015.jpg&#39;) . Print images of top-10 similar shirts . import glob import matplotlib.pyplot as plt import matplotlib.image as mpimg %matplotlib inline images = [] for shirt in closest_shirts: shirt = &#39;shirts/&#39;+shirt+&#39;.jpg&#39; for img_path in glob.glob(shirt): images.append(mpimg.imread(img_path)) plt.figure(figsize=(20,10)) columns = 5 for i, image in enumerate(images): plt.subplot(len(images) / columns + 1, columns, i + 1) plt.imshow(image) . Model persistence . from sklearn.externals import joblib joblib.dump(similarity, &#39;similarity.pkl&#39;) joblib.dump(shirt_id_to_matrix_id, &#39;shirt_id_to_matrix_id.pkl&#39;) joblib.dump(matrix_id_to_shirt_id, &#39;matrix_id_to_shirt_id.pkl&#39;) . loaded_model = joblib.load(&#39;similarity.pkl&#39;) . closest_ids = np.argsort(loaded_model[target_id, :])[::-1][0:10] closest_shirts = [matrix_id_to_shirt_id[matrix_id] for matrix_id in closest_ids] closest_shirts . [&#39;1015&#39;, &#39;1308&#39;, &#39;1187&#39;, &#39;2554&#39;, &#39;2420&#39;, &#39;2526&#39;, &#39;1174&#39;, &#39;2197&#39;, &#39;2545&#39;, &#39;1290&#39;] . . Credits .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/similarity%20vision%20retail/2021/04/23/similar-product-recommender.html",
            "relUrl": "/similarity%20vision%20retail/2021/04/23/similar-product-recommender.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Simulating a news personalization scenario using Contextual Bandits",
            "content": "In the Contextual Bandit(CB) introduction tutorial, we learnt about CB and different CB algorithms. In this tutorial we will simulate the scenario of personalizing news content on a site, using CB, to users. The goal is to maximize user engagement quantified by measuring click through rate (CTR). . Let&#39;s recall that in a CB setting, a data point has four components, . Context | Action | Probability of choosing action | Reward/cost for chosen action | . In our simulator, we will need to generate a context, get an action/decision for the given context and also simulate generating a reward. . In our simulator, our goal is to maximize reward (click through rate/CTR) or minimize loss (-CTR) . We have two website visitors: &#39;Tom&#39; and &#39;Anna&#39; | Each of them may visit the website either in the morning or in the afternoon | . The context is therefore (user, time_of_day) . We have the option of recommending a variety of articles to Tom and Anna. Therefore, actions are the different choices of articles: &quot;politics&quot;, &quot;sports&quot;, &quot;music&quot;, &quot;food&quot;, &quot;finance&quot;, &quot;health&quot;, &quot;cheese&quot; . The reward is whether they click on the article or not: &#39;click&#39; or &#39;no click&#39; . Let&#39;s first start with importing the necessary packages: . Simulate reward . In the real world, we will have to learn Tom and Anna&#39;s preferences for articles as we observe their interactions. Since this is a simulation, we will have to define Tom and Anna&#39;s preference profile. The reward that we provide to the learner will follow this preference profile. Our hope is to see if the learner can take better and better decisions as we see more samples which in turn means we are maximizing the reward. . We will also modify the reward function in a few different ways and see if the CB learner picks up the changes. We will compare the CTR with and without learning. . VW optimizes to minimize cost which is negative of reward. Therefore, we will always pass negative of reward as cost to VW. . USER_LIKED_ARTICLE = -1.0 USER_DISLIKED_ARTICLE = 0.0 . The reward function below specifies that Tom likes politics in the morning and music in the afternoon whereas Anna likes sports in the morning and politics in the afternoon. It looks dense but we are just simulating our hypothetical world in the format of the feedback the learner understands: cost. If the learner recommends an article that aligns with the reward function, we give a positive reward. In our simulated world this is a click. . def get_cost(context,action): if context[&#39;user&#39;] == &quot;Tom&quot;: if context[&#39;time_of_day&#39;] == &quot;morning&quot; and action == &#39;politics&#39;: return USER_LIKED_ARTICLE elif context[&#39;time_of_day&#39;] == &quot;afternoon&quot; and action == &#39;music&#39;: return USER_LIKED_ARTICLE else: return USER_DISLIKED_ARTICLE elif context[&#39;user&#39;] == &quot;Anna&quot;: if context[&#39;time_of_day&#39;] == &quot;morning&quot; and action == &#39;sports&#39;: return USER_LIKED_ARTICLE elif context[&#39;time_of_day&#39;] == &quot;afternoon&quot; and action == &#39;politics&#39;: return USER_LIKED_ARTICLE else: return USER_DISLIKED_ARTICLE . Understanding VW format . There are some things we need to do to get our input into a format VW understands. This function handles converting from our context as a dictionary, list of articles and the cost if there is one into the text format VW understands. . def to_vw_example_format(context, actions, cb_label = None): if cb_label is not None: chosen_action, cost, prob = cb_label example_string = &quot;&quot; example_string += &quot;shared |User user={} time_of_day={} n&quot;.format(context[&quot;user&quot;], context[&quot;time_of_day&quot;]) for action in actions: if cb_label is not None and action == chosen_action: example_string += &quot;0:{}:{} &quot;.format(cost, prob) example_string += &quot;|Action article={} n&quot;.format(action) #Strip the last newline return example_string[:-1] . To understand what&#39;s going on here let&#39;s go through an example. Here, it&#39;s the morning and the user is Tom. There are four possible articles. So in the VW format there is one line that starts with shared, this is the shared context, followed by four lines each corresponding to an article. . context = {&quot;user&quot;:&quot;Tom&quot;,&quot;time_of_day&quot;:&quot;morning&quot;} actions = [&quot;politics&quot;, &quot;sports&quot;, &quot;music&quot;, &quot;food&quot;] print(to_vw_example_format(context,actions)) . shared |User user=Tom time_of_day=morning |Action article=politics |Action article=sports |Action article=music |Action article=food . Getting a decision . When we call VW we get a pmf, probability mass function, as the output. Since we are incorporating exploration into our strategy, VW will give us a list of probabilities over the set of actions. This means that the probability at a given index in the list corresponds to the likelihood of picking that specific action. In order to arrive at a decision/action, we will have to sample from this list. . So, given a list [0.7, 0.1, 0.1, 0.1], we would choose the first item with a 70% chance. sample_custom_pmf takes such a list and gives us the index it chose and what the probability of choosing that index was. . def sample_custom_pmf(pmf): total = sum(pmf) scale = 1/total pmf = [x * scale for x in pmf] draw = random.random() sum_prob = 0.0 for index, prob in enumerate(pmf): sum_prob += prob if(sum_prob &gt; draw): return index, prob . We have all of the information we need to choose an action for a specific user and context. To use VW to achieve this, we will do the following: . We convert our context and actions into the text format we need | We pass this example to vw and get the pmf out | Now, we sample this pmf to get what article we will end up showing | Finally we return the article chosen, and the probability of choosing it (we are going to need the probability when we learn form this example) | def get_action(vw, context, actions): vw_text_example = to_vw_example_format(context,actions) pmf = vw.predict(vw_text_example) chosen_action_index, prob = sample_custom_pmf(pmf) return actions[chosen_action_index], prob . Simulation set up . Now that we have done all of the setup work and know how to interface with VW, let&#39;s simulate the world of Tom and Anna. The scenario is they go to a website and are shown an article. Remember that the reward function allows us to define the worlds reaction to what VW recommends. . We will choose between Tom and Anna uniformly at random and also choose their time of visit uniformly at random. You can think of this as us tossing a coin to choose between Tom and Anna (Anna if heads and Tom if tails) and another coin toss for choosing time of day. . actions camping finance food health music politics sports . users times_of_day . Anna afternoon 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -1.0 | 0.0 | . morning 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -1.0 | . Tom afternoon 0.0 | 0.0 | 0.0 | 0.0 | -1.0 | 0.0 | 0.0 | . morning 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | -1.0 | 0.0 | . We will instantiate a CB learner in VW and then simulate Tom and Anna&#39;s website visits num_iterations number of times. In each visit, we: . Decide between Tom and Anna | Decide time of day | Pass context i.e. (user, time of day) to learner to get action i.e. article recommendation and probability of choosing action | Receive reward i.e. see if user clicked or not. Remember that cost is just negative reward. | Format context, action, probability, reward in VW format | Learn from the example VW reduces a CB problem to a cost sensitive multiclass classification problem. | . | This is the same for every one of our simulations, so we define the process in the run_simulation function. The cost function must be supplied as this is essentially us simulating how the world works. . def run_simulation(vw, num_iterations, users, times_of_day, actions, cost_function, do_learn = True): cost_sum = 0. ctr = [] for i in range(1, num_iterations+1): # 1. In each simulation choose a user user = choose_user(users) # 2. Choose time of day for a given user time_of_day = choose_time_of_day(times_of_day) # 3. Pass context to vw to get an action context = {&#39;user&#39;: user, &#39;time_of_day&#39;: time_of_day} action, prob = get_action(vw, context, actions) # 4. Get cost of the action we chose cost = cost_function(context, action) cost_sum += cost if do_learn: # 5. Inform VW of what happened so we can learn from it vw_format = vw.parse(to_vw_example_format(context, actions, (action, cost, prob)),pyvw.vw.lContextualBandit) # 6. Learn vw.learn(vw_format) # We negate this so that on the plot instead of minimizing cost, we are maximizing reward ctr.append(-1*cost_sum/i) return ctr . We want to be able to visualize what is occurring, so we are going to plot the click through rate over each iteration of the simulation. If VW is showing actions the get rewards the ctr will be higher. Below is a little utility function to make showing the plot easier. . Scenario 1 . We will use the first reward function get_cost and assume that Tom and Anna do not change their preferences over time and see what happens to user engagement as we learn. We will also see what happens when there is no learning. We will use the &quot;no learning&quot; case as our baseline to compare to. . With learning . vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations = 5000 ctr = run_simulation(vw, num_iterations, users, times_of_day, actions, get_cost) plot_ctr(num_iterations, ctr) . Aside: interactions . You&#39;ll notice in the arguments we supply to VW, we include -q UA. This is telling VW to create additional features which are the features in the (U)ser namespace and (A)ction namespaces multiplied together. This allows us to learn the interaction between when certain actions are good in certain times of days and for particular users. If we didn&#39;t do that, the learning wouldn&#39;t really work. We can see that in action below. . vw = pyvw.vw(&quot;--cb_explore_adf --quiet --epsilon 0.2&quot;) num_iterations = 5000 ctr = run_simulation(vw, num_iterations, users, times_of_day, actions, get_cost) plot_ctr(num_iterations, ctr) . Without learning . Let&#39;s do the same thing again (but with -q, but this time show the effect if we don&#39;t learn from what happens. The ctr never improves are we just hover around 0.2. . vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations = 5000 ctr = run_simulation(vw, num_iterations, users, times_of_day, actions, get_cost, do_learn=False) plot_ctr(num_iterations, ctr) . Scenario 2 . In the real world people&#39;s preferences change over time. So now in the simulation we are going to incorporate two different cost functions, and swap over to the second one halfway through. Below is a a table of the new reward function we are going to use, get_cost_1: . Tom . get_cost get_cost_new1 . Morning | Politics | Politics | . Afternoon | Music | Sports | . Anna . get_cost get_cost_new1 . Morning | Sports | Sports | . Afternoon | Politics | Sports | . This reward function is still working with actions that the learner has seen previously. . To make it easy to show the effect of the cost function changing we are going to modify the run_simulation function. It is a little less readable now, but it supports accepting a list of cost functions and it will operate over each cost function in turn. This is perfect for what we need. . With learning . Let us now switch to the second reward function after a few samples (running the first reward function). Recall that this reward function changes the preferences of the web users but it is still working with the same action space as before. We should see the learner pick up these changes and optimize towards the new preferences. . # Instantiate learner in VW vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations_per_cost_func = 5000 cost_functions = [get_cost, get_cost_new1] total_iterations = num_iterations_per_cost_func * len(cost_functions) ctr = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions) plot_ctr(total_iterations, ctr) . Note: The initial spike in CTR depends on the rewards received for the first few examples. When you run on your own, you may see something different initially because our simulator is designed to have randomness. . Without learning . # use first reward function initially and then switch to second reward function # Instantiate learner in VW vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations_per_cost_func = 5000 cost_functions = [get_cost, get_cost_new1] total_iterations = num_iterations_per_cost_func * len(cost_functions) ctr = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions, do_learn=False) plot_ctr(total_iterations, ctr) . Scenario 3 . In this scenario we are going to start rewarding actions that have never seen a reward previously when we change the cost function. . Tom . get_cost get_cost_new2 . Morning | Politics | Politics | . Afternoon | Music | Food | . Anna . get_cost get_cost_new2 . Morning | Sports | Food | . Afternoon | Politics | Food | . def get_cost_new2(context,action): if context[&#39;user&#39;] == &quot;Tom&quot;: if context[&#39;time_of_day&#39;] == &quot;morning&quot; and action == &#39;politics&#39;: return USER_LIKED_ARTICLE elif context[&#39;time_of_day&#39;] == &quot;afternoon&quot; and action == &#39;food&#39;: return USER_LIKED_ARTICLE else: return USER_DISLIKED_ARTICLE elif context[&#39;user&#39;] == &quot;Anna&quot;: if context[&#39;time_of_day&#39;] == &quot;morning&quot; and action == &#39;food&#39;: return USER_LIKED_ARTICLE elif context[&#39;time_of_day&#39;] == &quot;afternoon&quot; and action == &#39;food&#39;: return USER_LIKED_ARTICLE else: return USER_DISLIKED_ARTICLE . With learning . Let us now switch to the third reward function after a few samples (running the first reward function). Recall that this reward function changes the preferences of the users and is working with a different action space than before. We should see the learner pick up these changes and optimize towards the new preferences . # Instantiate learner in VW vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations_per_cost_func = 5000 cost_functions = [get_cost, get_cost_new2] total_iterations = num_iterations_per_cost_func * len(cost_functions) ctr = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions) plot_ctr(total_iterations, ctr) . Without Learning . # use first reward function initially and then switch to third reward function # Instantiate learner in VW vw = pyvw.vw(&quot;--cb_explore_adf -q UA --quiet --epsilon 0.2&quot;) num_iterations_per_cost_func = 5000 cost_functions = [get_cost, get_cost_new2] total_iterations = num_iterations_per_cost_func * len(cost_functions) ctr = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions, do_learn=False) plot_ctr(total_iterations, ctr) . Summary . This tutorial aimed at showcasing a real world scenario where contextual bandit algorithms can be used. We were able to take a context and set of actions and learn what actions worked best for a given context. We saw that the learner was able to respond rapidly to changes in the world. We showed that allowing the learner to interact with the world resulted in higher rewards than the no learning baseline. . This tutorial worked with simplistic features. VW supports high dimensional sparse features, different exploration algorithms and policy evaluation approaches. . credits .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/reinforcement%20contextual/2021/04/22/vowpal-wabbit-contextual-recommender.html",
            "relUrl": "/reinforcement%20contextual/2021/04/22/vowpal-wabbit-contextual-recommender.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Neural Matrix Factorization from scratch in PyTorch",
            "content": "!pip install -q tensorboardX . |████████████████████████████████| 122kB 8.3MB/s . import os import time import random import argparse import numpy as np import pandas as pd import torch import torch.nn as nn import torch.optim as optim import torch.utils.data as data from tensorboardX import SummaryWriter . Downloading Movielens-1M Ratings . DATA_URL = &quot;https://raw.githubusercontent.com/sparsh-ai/rec-data-public/master/ml-1m-dat/ratings.dat&quot; MAIN_PATH = &#39;/content/&#39; DATA_PATH = MAIN_PATH + &#39;ratings.dat&#39; MODEL_PATH = MAIN_PATH + &#39;models/&#39; MODEL = &#39;ml-1m_Neu_MF&#39; . !wget -nc https://raw.githubusercontent.com/sparsh-ai/rec-data-public/master/ml-1m-dat/ratings.dat . Defining Dataset Classes . class Rating_Datset(torch.utils.data.Dataset): def __init__(self, user_list, item_list, rating_list): super(Rating_Datset, self).__init__() self.user_list = user_list self.item_list = item_list self.rating_list = rating_list def __len__(self): return len(self.user_list) def __getitem__(self, idx): user = self.user_list[idx] item = self.item_list[idx] rating = self.rating_list[idx] return ( torch.tensor(user, dtype=torch.long), torch.tensor(item, dtype=torch.long), torch.tensor(rating, dtype=torch.float) ) . NCF Dataset Class . _reindex: process dataset to reindex userID and itemID, also set rating as binary feedback | _leave_one_out: leave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf | negative_sampling: randomly selects n negative examples for each positive one | . class NCF_Data(object): &quot;&quot;&quot; Construct Dataset for NCF &quot;&quot;&quot; def __init__(self, args, ratings): self.ratings = ratings self.num_ng = args.num_ng self.num_ng_test = args.num_ng_test self.batch_size = args.batch_size self.preprocess_ratings = self._reindex(self.ratings) self.user_pool = set(self.ratings[&#39;user_id&#39;].unique()) self.item_pool = set(self.ratings[&#39;item_id&#39;].unique()) self.train_ratings, self.test_ratings = self._leave_one_out(self.preprocess_ratings) self.negatives = self._negative_sampling(self.preprocess_ratings) random.seed(args.seed) def _reindex(self, ratings): &quot;&quot;&quot; Process dataset to reindex userID and itemID, also set rating as binary feedback &quot;&quot;&quot; user_list = list(ratings[&#39;user_id&#39;].drop_duplicates()) user2id = {w: i for i, w in enumerate(user_list)} item_list = list(ratings[&#39;item_id&#39;].drop_duplicates()) item2id = {w: i for i, w in enumerate(item_list)} ratings[&#39;user_id&#39;] = ratings[&#39;user_id&#39;].apply(lambda x: user2id[x]) ratings[&#39;item_id&#39;] = ratings[&#39;item_id&#39;].apply(lambda x: item2id[x]) ratings[&#39;rating&#39;] = ratings[&#39;rating&#39;].apply(lambda x: float(x &gt; 0)) return ratings def _leave_one_out(self, ratings): &quot;&quot;&quot; leave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf &quot;&quot;&quot; ratings[&#39;rank_latest&#39;] = ratings.groupby([&#39;user_id&#39;])[&#39;timestamp&#39;].rank(method=&#39;first&#39;, ascending=False) test = ratings.loc[ratings[&#39;rank_latest&#39;] == 1] train = ratings.loc[ratings[&#39;rank_latest&#39;] &gt; 1] assert train[&#39;user_id&#39;].nunique()==test[&#39;user_id&#39;].nunique(), &#39;Not Match Train User with Test User&#39; return train[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]], test[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]] def _negative_sampling(self, ratings): interact_status = ( ratings.groupby(&#39;user_id&#39;)[&#39;item_id&#39;] .apply(set) .reset_index() .rename(columns={&#39;item_id&#39;: &#39;interacted_items&#39;})) interact_status[&#39;negative_items&#39;] = interact_status[&#39;interacted_items&#39;].apply(lambda x: self.item_pool - x) interact_status[&#39;negative_samples&#39;] = interact_status[&#39;negative_items&#39;].apply(lambda x: random.sample(x, self.num_ng_test)) return interact_status[[&#39;user_id&#39;, &#39;negative_items&#39;, &#39;negative_samples&#39;]] def get_train_instance(self): users, items, ratings = [], [], [] train_ratings = pd.merge(self.train_ratings, self.negatives[[&#39;user_id&#39;, &#39;negative_items&#39;]], on=&#39;user_id&#39;) train_ratings[&#39;negatives&#39;] = train_ratings[&#39;negative_items&#39;].apply(lambda x: random.sample(x, self.num_ng)) for row in train_ratings.itertuples(): users.append(int(row.user_id)) items.append(int(row.item_id)) ratings.append(float(row.rating)) for i in range(self.num_ng): users.append(int(row.user_id)) items.append(int(row.negatives[i])) ratings.append(float(0)) # negative samples get 0 rating dataset = Rating_Datset( user_list=users, item_list=items, rating_list=ratings) return torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4) def get_test_instance(self): users, items, ratings = [], [], [] test_ratings = pd.merge(self.test_ratings, self.negatives[[&#39;user_id&#39;, &#39;negative_samples&#39;]], on=&#39;user_id&#39;) for row in test_ratings.itertuples(): users.append(int(row.user_id)) items.append(int(row.item_id)) ratings.append(float(row.rating)) for i in getattr(row, &#39;negative_samples&#39;): users.append(int(row.user_id)) items.append(int(i)) ratings.append(float(0)) dataset = Rating_Datset( user_list=users, item_list=items, rating_list=ratings) return torch.utils.data.DataLoader(dataset, batch_size=self.num_ng_test+1, shuffle=False, num_workers=2) . Defining Metrics . Using Hit Rate and NDCG as our evaluation metrics . def hit(ng_item, pred_items): if ng_item in pred_items: return 1 return 0 def ndcg(ng_item, pred_items): if ng_item in pred_items: index = pred_items.index(ng_item) return np.reciprocal(np.log2(index+2)) return 0 def metrics(model, test_loader, top_k, device): HR, NDCG = [], [] for user, item, label in test_loader: user = user.to(device) item = item.to(device) predictions = model(user, item) _, indices = torch.topk(predictions, top_k) recommends = torch.take( item, indices).cpu().numpy().tolist() ng_item = item[0].item() # leave one-out evaluation has only one item per user HR.append(hit(ng_item, recommends)) NDCG.append(ndcg(ng_item, recommends)) return np.mean(HR), np.mean(NDCG) . Defining Model Architectures . Generalized Matrix Factorization | Multi Layer Perceptron | Neural Matrix Factorization | class Generalized_Matrix_Factorization(nn.Module): def __init__(self, args, num_users, num_items): super(Generalized_Matrix_Factorization, self).__init__() self.num_users = num_users self.num_items = num_items self.factor_num = args.factor_num self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num) self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num) self.affine_output = nn.Linear(in_features=self.factor_num, out_features=1) self.logistic = nn.Sigmoid() def forward(self, user_indices, item_indices): user_embedding = self.embedding_user(user_indices) item_embedding = self.embedding_item(item_indices) element_product = torch.mul(user_embedding, item_embedding) logits = self.affine_output(element_product) rating = self.logistic(logits) return rating def init_weight(self): pass . class Multi_Layer_Perceptron(nn.Module): def __init__(self, args, num_users, num_items): super(Multi_Layer_Perceptron, self).__init__() self.num_users = num_users self.num_items = num_items self.factor_num = args.factor_num self.layers = args.layers self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num) self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num) self.fc_layers = nn.ModuleList() for idx, (in_size, out_size) in enumerate(zip(self.layers[:-1], self.layers[1:])): self.fc_layers.append(nn.Linear(in_size, out_size)) self.affine_output = nn.Linear(in_features=self.layers[-1], out_features=1) self.logistic = nn.Sigmoid() def forward(self, user_indices, item_indices): user_embedding = self.embedding_user(user_indices) item_embedding = self.embedding_item(item_indices) vector = torch.cat([user_embedding, item_embedding], dim=-1) # the concat latent vector for idx, _ in enumerate(range(len(self.fc_layers))): vector = self.fc_layers[idx](vector) vector = nn.ReLU()(vector) # vector = nn.BatchNorm1d()(vector) # vector = nn.Dropout(p=0.5)(vector) logits = self.affine_output(vector) rating = self.logistic(logits) return rating def init_weight(self): pass . class NeuMF(nn.Module): def __init__(self, args, num_users, num_items): super(NeuMF, self).__init__() self.num_users = num_users self.num_items = num_items self.factor_num_mf = args.factor_num self.factor_num_mlp = int(args.layers[0]/2) self.layers = args.layers self.dropout = args.dropout self.embedding_user_mlp = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mlp) self.embedding_item_mlp = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mlp) self.embedding_user_mf = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mf) self.embedding_item_mf = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mf) self.fc_layers = nn.ModuleList() for idx, (in_size, out_size) in enumerate(zip(args.layers[:-1], args.layers[1:])): self.fc_layers.append(torch.nn.Linear(in_size, out_size)) self.fc_layers.append(nn.ReLU()) self.affine_output = nn.Linear(in_features=args.layers[-1] + self.factor_num_mf, out_features=1) self.logistic = nn.Sigmoid() self.init_weight() def init_weight(self): nn.init.normal_(self.embedding_user_mlp.weight, std=0.01) nn.init.normal_(self.embedding_item_mlp.weight, std=0.01) nn.init.normal_(self.embedding_user_mf.weight, std=0.01) nn.init.normal_(self.embedding_item_mf.weight, std=0.01) for m in self.fc_layers: if isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) nn.init.xavier_uniform_(self.affine_output.weight) for m in self.modules(): if isinstance(m, nn.Linear) and m.bias is not None: m.bias.data.zero_() def forward(self, user_indices, item_indices): user_embedding_mlp = self.embedding_user_mlp(user_indices) item_embedding_mlp = self.embedding_item_mlp(item_indices) user_embedding_mf = self.embedding_user_mf(user_indices) item_embedding_mf = self.embedding_item_mf(item_indices) mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1) mf_vector =torch.mul(user_embedding_mf, item_embedding_mf) for idx, _ in enumerate(range(len(self.fc_layers))): mlp_vector = self.fc_layers[idx](mlp_vector) vector = torch.cat([mlp_vector, mf_vector], dim=-1) logits = self.affine_output(vector) rating = self.logistic(logits) return rating.squeeze() . Setting Arguments . Here is the brief description of important ones: . Learning rate is 0.001 | Dropout rate is 0.2 | Running for 10 epochs | HitRate@10 and NDCG@10 | 4 negative samples for each positive one | . parser = argparse.ArgumentParser() parser.add_argument(&quot;--seed&quot;, type=int, default=42, help=&quot;Seed&quot;) parser.add_argument(&quot;--lr&quot;, type=float, default=0.001, help=&quot;learning rate&quot;) parser.add_argument(&quot;--dropout&quot;, type=float, default=0.2, help=&quot;dropout rate&quot;) parser.add_argument(&quot;--batch_size&quot;, type=int, default=256, help=&quot;batch size for training&quot;) parser.add_argument(&quot;--epochs&quot;, type=int, default=10, help=&quot;training epoches&quot;) parser.add_argument(&quot;--top_k&quot;, type=int, default=10, help=&quot;compute metrics@top_k&quot;) parser.add_argument(&quot;--factor_num&quot;, type=int, default=32, help=&quot;predictive factors numbers in the model&quot;) parser.add_argument(&quot;--layers&quot;, nargs=&#39;+&#39;, default=[64,32,16,8], help=&quot;MLP layers. Note that the first layer is the concatenation of user and item embeddings. So layers[0]/2 is the embedding size.&quot;) parser.add_argument(&quot;--num_ng&quot;, type=int, default=4, help=&quot;Number of negative samples for training set&quot;) parser.add_argument(&quot;--num_ng_test&quot;, type=int, default=100, help=&quot;Number of negative samples for test set&quot;) parser.add_argument(&quot;--out&quot;, default=True, help=&quot;save model or not&quot;) . . _StoreAction(option_strings=[&#39;--out&#39;], dest=&#39;out&#39;, nargs=None, const=None, default=True, type=None, choices=None, help=&#39;save model or not&#39;, metavar=None) . Training NeuMF Model . args = parser.parse_args(&quot;&quot;) device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) writer = SummaryWriter() # seed for Reproducibility seed_everything(args.seed) # load data ml_1m = pd.read_csv( DATA_PATH, sep=&quot;::&quot;, names = [&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;, &#39;timestamp&#39;], engine=&#39;python&#39;) # set the num_users, items num_users = ml_1m[&#39;user_id&#39;].nunique()+1 num_items = ml_1m[&#39;item_id&#39;].nunique()+1 # construct the train and test datasets data = NCF_Data(args, ml_1m) train_loader = data.get_train_instance() test_loader = data.get_test_instance() # set model and loss, optimizer model = NeuMF(args, num_users, num_items) model = model.to(device) loss_function = nn.BCELoss() optimizer = optim.Adam(model.parameters(), lr=args.lr) # train, evaluation best_hr = 0 for epoch in range(1, args.epochs+1): model.train() # Enable dropout (if have). start_time = time.time() for user, item, label in train_loader: user = user.to(device) item = item.to(device) label = label.to(device) optimizer.zero_grad() prediction = model(user, item) loss = loss_function(prediction, label) loss.backward() optimizer.step() writer.add_scalar(&#39;loss/Train_loss&#39;, loss.item(), epoch) model.eval() HR, NDCG = metrics(model, test_loader, args.top_k, device) writer.add_scalar(&#39;Perfomance/HR@10&#39;, HR, epoch) writer.add_scalar(&#39;Perfomance/NDCG@10&#39;, NDCG, epoch) elapsed_time = time.time() - start_time print(&quot;The time elapse of epoch {:03d}&quot;.format(epoch) + &quot; is: &quot; + time.strftime(&quot;%H: %M: %S&quot;, time.gmtime(elapsed_time))) print(&quot;HR: {:.3f} tNDCG: {:.3f}&quot;.format(np.mean(HR), np.mean(NDCG))) if HR &gt; best_hr: best_hr, best_ndcg, best_epoch = HR, NDCG, epoch if args.out: if not os.path.exists(MODEL_PATH): os.mkdir(MODEL_PATH) torch.save(model, &#39;{}{}.pth&#39;.format(MODEL_PATH, MODEL)) writer.close() . /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary. cpuset_checked)) . The time elapse of epoch 001 is: 00: 02: 30 HR: 0.624 NDCG: 0.362 The time elapse of epoch 002 is: 00: 02: 31 HR: 0.663 NDCG: 0.392 The time elapse of epoch 003 is: 00: 02: 30 HR: 0.673 NDCG: 0.399 The time elapse of epoch 004 is: 00: 02: 30 HR: 0.677 NDCG: 0.402 The time elapse of epoch 005 is: 00: 02: 31 HR: 0.671 NDCG: 0.399 The time elapse of epoch 006 is: 00: 02: 32 HR: 0.671 NDCG: 0.400 The time elapse of epoch 007 is: 00: 02: 32 HR: 0.669 NDCG: 0.400 The time elapse of epoch 008 is: 00: 02: 31 HR: 0.665 NDCG: 0.395 The time elapse of epoch 009 is: 00: 02: 33 HR: 0.664 NDCG: 0.393 The time elapse of epoch 010 is: 00: 02: 32 HR: 0.667 NDCG: 0.394 . Final Output . print(&quot;Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}&quot;.format( best_epoch, best_hr, best_ndcg)) .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/matrixfactorization%20movielens%20pytorch%20scratch/2021/04/21/rec-algo-ncf-pytorch-pyy0715.html",
            "relUrl": "/matrixfactorization%20movielens%20pytorch%20scratch/2021/04/21/rec-algo-ncf-pytorch-pyy0715.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Large-scale Document Retrieval with ElasticSearch",
            "content": "Retrieval Flow Overview . . Part 1 - Setting up Elasticsearch . Download the elasticsearch archive (linux), setup a local server | Create a client connection to the local elasticsearch instance | . # download the latest elasticsearch version !wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.11.1-linux-x86_64.tar.gz !tar -xzvf elasticsearch-7.11.1-linux-x86_64.tar.gz !chown -R daemon:daemon elasticsearch-7.11.1 # prep the elasticsearch server import os from subprocess import Popen, PIPE, STDOUT es_subprocess = Popen([&#39;elasticsearch-7.11.1/bin/elasticsearch&#39;], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda : os.setuid(1)) # wait for a few minutes for the local host to start !curl -X GET &quot;localhost:9200/&quot; # install elasticsearch python api !pip install -q elasticsearch . # check if elasticsearch server is properly running in the background from elasticsearch import Elasticsearch, helpers es_client = Elasticsearch([&#39;localhost&#39;]) es_client.info() . {&#39;cluster_name&#39;: &#39;elasticsearch&#39;, &#39;cluster_uuid&#39;: &#39;WQS1QVG8RX6FQ65LS6MyrA&#39;, &#39;name&#39;: &#39;50176241ce38&#39;, &#39;tagline&#39;: &#39;You Know, for Search&#39;, &#39;version&#39;: {&#39;build_date&#39;: &#39;2021-02-15T13:44:09.394032Z&#39;, &#39;build_flavor&#39;: &#39;default&#39;, &#39;build_hash&#39;: &#39;ff17057114c2199c9c1bbecc727003a907c0db7a&#39;, &#39;build_snapshot&#39;: False, &#39;build_type&#39;: &#39;tar&#39;, &#39;lucene_version&#39;: &#39;8.7.0&#39;, &#39;minimum_index_compatibility_version&#39;: &#39;6.0.0-beta1&#39;, &#39;minimum_wire_compatibility_version&#39;: &#39;6.8.0&#39;, &#39;number&#39;: &#39;7.11.1&#39;}} . . Part 2 - Walking through an embedding-based retrieval system . Download MovieLens dataset . !wget https://files.grouplens.org/datasets/movielens/ml-25m.zip --no-check-certificate !unzip ml-25m.zip . Archive: ml-25m.zip creating: ml-25m/ inflating: ml-25m/tags.csv inflating: ml-25m/links.csv inflating: ml-25m/README.txt inflating: ml-25m/ratings.csv inflating: ml-25m/genome-tags.csv inflating: ml-25m/genome-scores.csv inflating: ml-25m/movies.csv . import pandas as pd data = pd.read_csv(&#39;ml-25m/movies.csv&#39;).drop_duplicates() data.head() . movieId title genres . 0 1 | Toy Story (1995) | Adventure|Animation|Children|Comedy|Fantasy | . 1 2 | Jumanji (1995) | Adventure|Children|Fantasy | . 2 3 | Grumpier Old Men (1995) | Comedy|Romance | . 3 4 | Waiting to Exhale (1995) | Comedy|Drama|Romance | . 4 5 | Father of the Bride Part II (1995) | Comedy | . Build index with document vectors . import tensorflow_hub as hub from timeit import default_timer as timer import json . embed = hub.load(&quot;https://tfhub.dev/google/universal-sentence-encoder-large/5&quot;) . INDEX_NAME = &quot;movie_title&quot; BATCH_SIZE = 200 SEARCH_SIZE = 10 MAPPINGS = { &#39;mappings&#39;: {&#39;_source&#39;: {&#39;enabled&#39;: &#39;true&#39;}, &#39;dynamic&#39;: &#39;true&#39;, &#39;properties&#39;: {&#39;title_vector&#39;: {&#39;dims&#39;: 512, &#39;type&#39;: &#39;dense_vector&#39;}, &#39;movie_id&#39;: {&#39;type&#39;: &#39;keyword&#39;}, &#39;genres&#39;: {&#39;type&#39;: &#39;keyword&#39;} } }, &#39;settings&#39;: {&#39;number_of_replicas&#39;: 1, &#39;number_of_shards&#39;:2} } . Ref - https://youtu.be/F4D08uU3mPA . index_movie_lens(data, num_doc=2000) . creating the movie_title index. Indexed 400 documents in 27.59 seconds. Indexed 800 documents in 48.96 seconds. Indexed 1200 documents in 70.18 seconds. Indexed 1600 documents in 90.92 seconds. Indexed 2000 documents in 111.85 seconds. Done indexing 2000 documents in 111.85 seconds . Search with query vector . return_top_movies(&quot;war&quot;) . 2000 total hits. id: 335, score: 0.5282537 {&#39;genres&#39;: &#39;Adventure|Drama|War&#39;, &#39;title&#39;: &#39;War, The (1994)&#39;} id: 712, score: 0.43743240000000005 {&#39;genres&#39;: &#39;Documentary&#39;, &#39;title&#39;: &#39;War Stories (1995)&#39;} id: 1493, score: 0.3954858000000001 {&#39;genres&#39;: &#39;Drama&#39;, &#39;title&#39;: &#39;War at Home, The (1996)&#39;} id: 1362, score: 0.32700850000000004 {&#39;genres&#39;: &#39;Romance|War&#39;, &#39;title&#39;: &#39;In Love and War (1996)&#39;} id: 550, score: 0.3104720000000001 {&#39;genres&#39;: &#39;Documentary&#39;, &#39;title&#39;: &#39;War Room, The (1993)&#39;} id: 1828, score: 0.30568780000000007 {&#39;genres&#39;: &#39;Action|Romance|Sci-Fi|Thriller&#39;, &#39;title&#39;: &#39;Armageddon (1998)&#39;} id: 1932, score: 0.3055576 {&#39;genres&#39;: &#39;Adventure|Sci-Fi&#39;, &#39;title&#39;: &#39;Dune (1984)&#39;} id: 1265, score: 0.2961224 {&#39;genres&#39;: &#39;Drama|War&#39;, &#39;title&#39;: &#39;Killing Fields, The (1984)&#39;} id: 1063, score: 0.2951368999999999 {&#39;genres&#39;: &#39;Drama|War&#39;, &#39;title&#39;: &#39;Platoon (1986)&#39;} id: 1676, score: 0.2776048 {&#39;genres&#39;: &#39;Comedy&#39;, &#39;title&#39;: &#39;Senseless (1998)&#39;} . Part 3 - Approximate Nearest Neighbor (ANN) Algorithms . . !pip install faiss !pip install nmslib !apt-get install libomp-dev import faiss import nmslib . documents = data[&#39;title&#39;].to_list()[:2000] # # OOM for large document size embeddings = embed(documents).numpy() embeddings.shape . (2000, 512) . class DemoIndexLSH(): def __init__(self, dimension, documents, embeddings): self.dimension = dimension self.documents = documents self.embeddings = embeddings def build(self, num_bits=8): self.index = faiss.IndexLSH(self.dimension, num_bits) self.index.add(self.embeddings) def query(self, input_embedding, k=5): distances, indices = self.index.search(input_embedding, k) return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])] index_lsh = DemoIndexLSH(512, documents, embeddings) index_lsh.build(num_bits=16) . class DemoIndexIVFPQ(): def __init__(self, dimension, documents, embeddings): self.dimension = dimension self.documents = documents self.embeddings = embeddings def build(self, number_of_partition=2, number_of_subquantizers=2, subvector_bits=4): quantizer = faiss.IndexFlatL2(self.dimension) self.index = faiss.IndexIVFPQ(quantizer, self.dimension, number_of_partition, number_of_subquantizers, subvector_bits) self.index.train(self.embeddings) self.index.add(self.embeddings) def query(self, input_embedding, k=5): distances, indices = self.index.search(input_embedding, k) return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])] index_pq = DemoIndexIVFPQ(512, documents, embeddings) index_pq.build() . class DemoHNSW(): def __init__(self, dimension, documents, embeddings): self.dimension = dimension self.documents = documents self.embeddings = embeddings def build(self, num_bits=8): self.index = nmslib.init(method=&#39;hnsw&#39;, space=&#39;cosinesimil&#39;) self.index.addDataPointBatch(self.embeddings) self.index.createIndex({&#39;post&#39;: 2}, print_progress=True) def query(self, input_embedding, k=5): indices, distances = self.index.knnQuery(input_embedding, k) return [(distance, self.documents[index]) for distance, index in zip(distances, indices)] index_hnsw = DemoHNSW(512, documents, embeddings) index_hnsw.build() . class DemoIndexFlatL2(): def __init__(self, dimension, documents, embeddings): self.dimension = dimension self.documents = documents self.embeddings = embeddings def build(self, num_bits=8): self.index = faiss.IndexFlatL2(self.dimension) self.index.add(self.embeddings) def query(self, input_embedding, k=5): distances, indices = self.index.search(input_embedding, k) return [(distance, self.documents[index]) for distance, index in zip(distances[0], indices[0])] index_flat = DemoIndexFlatL2(512, documents, embeddings) index_flat.build() . def return_ann_top_movies(ann_index, query, k=SEARCH_SIZE): query_vector = embed([query]).numpy() search_start = timer() top_docs = ann_index.query(query_vector, k) search_time = timer() - search_start print(&quot;search time: {:.2f} ms&quot;.format(search_time * 1000)) return top_docs . return_ann_top_movies(index_flat, &quot;romance&quot;) . search time: 0.82 ms . [(0.95573366, &#39;True Romance (1993)&#39;), (1.2160163, &#39;Love Serenade (1996)&#39;), (1.2626679, &#39;Love Affair (1994)&#39;), (1.3447753, &#39;Kissed (1996)&#39;), (1.3752131, &#39;In Love and War (1996)&#39;), (1.3804029, &#39;Casablanca (1942)&#39;), (1.3832319, &#39;Flirt (1995)&#39;), (1.38626, &#39;Moonlight and Valentino (1995)&#39;), (1.3862813, &#39;Hotel de Love (1996)&#39;), (1.3907104, &#39;Intimate Relations (1996)&#39;)] . return_ann_top_movies(index_lsh, &quot;romance&quot;) . search time: 0.56 ms . [(2.0, &#39;Visitors, The (Visiteurs, Les) (1993)&#39;), (2.0, &#39;City Hall (1996)&#39;), (2.0, &#39;Paradise Road (1997)&#39;), (3.0, &#39;When a Man Loves a Woman (1994)&#39;), (3.0, &#39;Cosi (1996)&#39;), (3.0, &#39;Haunted World of Edward D. Wood Jr., The (1996)&#39;), (3.0, &#39;Eddie (1996)&#39;), (3.0, &#39;Ransom (1996)&#39;), (3.0, &#39;Time to Kill, A (1996)&#39;), (3.0, &#39;Mirage (1995)&#39;)] . return_ann_top_movies(index_pq, &quot;romance&quot;) . search time: 0.19 ms . [(1.07124, &#39;Streetcar Named Desire, A (1951)&#39;), (1.07124, &#39;Moonlight Murder (1936)&#39;), (1.0847104, &#39;To Kill a Mockingbird (1962)&#39;), (1.0847104, &#39;Meet John Doe (1941)&#39;), (1.0867723, &#39;Moonlight and Valentino (1995)&#39;), (1.0901785, &#39;Laura (1944)&#39;), (1.0901785, &#39;Rebecca (1940)&#39;), (1.0901785, &#39;African Queen, The (1951)&#39;), (1.0901785, &#39;Gigi (1958)&#39;), (1.0901785, &#39;Scarlet Letter, The (1926)&#39;)] . return_ann_top_movies(index_hnsw, &quot;romance&quot;) . search time: 0.29 ms . [(0.47786665, &#39;True Romance (1993)&#39;), (0.6080081, &#39;Love Serenade (1996)&#39;), (0.63133395, &#39;Love Affair (1994)&#39;), (0.6723877, &#39;Kissed (1996)&#39;), (0.6876065, &#39;In Love and War (1996)&#39;), (0.6916158, &#39;Flirt (1995)&#39;), (0.69312984, &#39;Moonlight and Valentino (1995)&#39;), (0.69314075, &#39;Hotel de Love (1996)&#39;), (0.69535506, &#39;Intimate Relations (1996)&#39;), (0.6985383, &#39;Love in Bloom (1935)&#39;)] .",
            "url": "https://sparsh-ai.github.io/rec-tutorials/large-scale%20elasticsearch/2021/04/20/dl-retrieval.html",
            "relUrl": "/large-scale%20elasticsearch/2021/04/20/dl-retrieval.html",
            "date": " • Apr 20, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sparsh-ai.github.io/rec-tutorials/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sparsh-ai.github.io/rec-tutorials/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}